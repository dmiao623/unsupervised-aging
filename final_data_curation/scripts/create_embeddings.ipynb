{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40af2f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f45d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import keypoint_moseq as kpms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90c91cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_aging_dir = Path(os.environ[\"UNSUPERVISED_AGING\"])\n",
    "kpms_dir = unsupervised_aging_dir / \"data/kpms_projects\"\n",
    "\n",
    "project_name, model_name = {\n",
    "    \"b6\": (\n",
    "        \"2025-07-03_kpms-v2\",\n",
    "        \"2025-07-07_model-2\"\n",
    "    ),\n",
    "    \"do\": (\n",
    "        \"2025-07-16_kpms-v3\",\n",
    "        \"2025-07-16_model-4\"\n",
    "    ),\n",
    "    \"c\": (\n",
    "        \"2025-09-20_kpms-v5_150_6\",\n",
    "        \"2025-09-21_model-1\"\n",
    "    )\n",
    "}[mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0fbf6145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving results for results-2.h5...\n",
      "Retrieving results for results.h5...\n",
      "Retrieving results for results-3.h5...\n"
     ]
    }
   ],
   "source": [
    "kpms_model_dir = kpms_dir / project_name / model_name\n",
    "\n",
    "def get_results(filename, path = kpms_model_dir):\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "         raise FileNotFoundError(f\"Path not found: {path}\")\n",
    "\n",
    "    target_file = path / filename\n",
    "    if not target_file.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {target_file}\")\n",
    "\n",
    "    if filename == \"results.h5\":\n",
    "        return kpms.load_results(path.parent, path.name)\n",
    "\n",
    "    results_path = path / \"results.h5\"\n",
    "    backup_path = path / \"results.h5.bak\"\n",
    "    has_existing_results = results_path.exists()\n",
    "    \n",
    "    if has_existing_results and backup_path.exists():\n",
    "        raise FileExistsError(f\"Backup file {backup_path} already exists. Cannot safely proceed.\")\n",
    "\n",
    "    try:\n",
    "        if has_existing_results:\n",
    "            results_path.rename(backup_path)\n",
    "        target_file.rename(results_path)\n",
    "\n",
    "        return kpms.load_results(path.parent, path.name)\n",
    "\n",
    "    finally:\n",
    "        if results_path.exists():\n",
    "            results_path.rename(target_file)\n",
    "        if has_existing_results and backup_path.exists():\n",
    "            backup_path.rename(results_path)\n",
    "\n",
    "agg_results = {}\n",
    "for result_file in kpms_model_dir.rglob(\"results*.h5\"):\n",
    "    result_filename = result_file.name\n",
    "    print(f\"Retrieving results for {result_filename}...\")\n",
    "\n",
    "    results = get_results(result_filename)\n",
    "    syllable_dict = {\n",
    "        name: entry[\"syllable\"] for name, entry in results.items()\n",
    "    }\n",
    "    agg_results |= syllable_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "989f922c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1223\n"
     ]
    }
   ],
   "source": [
    "print(len(agg_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "680537f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:01<00:00, 66.87it/s]\n"
     ]
    }
   ],
   "source": [
    "def _get_syllable_frequency_statistics(th: float = 0.0):\n",
    "    sequences = [info[\"syllable\"] for info in results.values()]\n",
    "    uniq = sorted({s for seq in sequences for s in seq})\n",
    "    if th > 0.0:\n",
    "        global_counts = {s: 0 for s in uniq}\n",
    "        for seq in sequences:\n",
    "            for s in seq:\n",
    "                global_counts[s] += 1\n",
    "        total = sum(global_counts.values())\n",
    "        uniq = [s for s in uniq if total and global_counts[s] / total >= th]\n",
    "\n",
    "    if not uniq:\n",
    "        return {}\n",
    "\n",
    "    idx = {s: i for i, s in enumerate(uniq)}\n",
    "    n = len(uniq)\n",
    "\n",
    "    out = {}\n",
    "    for s in uniq:\n",
    "        out[f\"avg_bout_length_{s}\"] = []\n",
    "        out[f\"total_duration_{s}\"] = []\n",
    "        out[f\"num_bouts_{s}\"] = []\n",
    "\n",
    "    for _, info in tqdm(results.items()):\n",
    "        seq = info[\"syllable\"]\n",
    "        dur = None\n",
    "        for k in (\"durations\", \"duration\", \"syllable_durations\", \"syllable_duration\"):\n",
    "            if k in info and hasattr(info[k], \"__len__\") and len(info[k]) == len(seq):\n",
    "                dur = info[k]\n",
    "                break\n",
    "\n",
    "        total_len = [0]*n\n",
    "        bout_cnt = [0]*n\n",
    "        sum_dur = [0.0]*n\n",
    "\n",
    "        prev = None\n",
    "        run_len = 0\n",
    "        for i, s in enumerate(seq):\n",
    "            if s == prev:\n",
    "                run_len += 1\n",
    "            else:\n",
    "                if prev in idx:\n",
    "                    j = idx[prev]\n",
    "                    total_len[j] += run_len\n",
    "                    bout_cnt[j] += 1\n",
    "                prev = s\n",
    "                run_len = 1\n",
    "            if s in idx and dur is not None:\n",
    "                sum_dur[idx[s]] += float(dur[i])\n",
    "\n",
    "        if prev in idx:\n",
    "            j = idx[prev]\n",
    "            total_len[j] += run_len\n",
    "            bout_cnt[j] += 1\n",
    "\n",
    "        if dur is None:\n",
    "            for j in range(n):\n",
    "                sum_dur[j] = float(total_len[j])\n",
    "\n",
    "        for j, s in enumerate(uniq):\n",
    "            abl = (total_len[j] / bout_cnt[j]) if bout_cnt[j] else 0.0\n",
    "            out[f\"avg_bout_length_{s}\"].append(abl)\n",
    "            out[f\"total_duration_{s}\"].append(sum_dur[j])\n",
    "            out[f\"num_bouts_{s}\"].append(int(bout_cnt[j]))\n",
    "\n",
    "    return out\n",
    "\n",
    "syllable_frequency_statistics = _get_syllable_frequency_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8be0d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NetworkFilename</th>\n",
       "      <th>latent_embedding_mean_0</th>\n",
       "      <th>latent_embedding_mean_1</th>\n",
       "      <th>latent_embedding_mean_2</th>\n",
       "      <th>latent_embedding_mean_3</th>\n",
       "      <th>latent_embedding_mean_4</th>\n",
       "      <th>latent_embedding_mean_5</th>\n",
       "      <th>latent_embedding_mean_6</th>\n",
       "      <th>latent_embedding_mean_7</th>\n",
       "      <th>latent_embedding_mean_8</th>\n",
       "      <th>...</th>\n",
       "      <th>grooming_duration_secs</th>\n",
       "      <th>Rearing_supported_T5</th>\n",
       "      <th>Rearing_supported_T20</th>\n",
       "      <th>Rearing_supported_T55</th>\n",
       "      <th>Rearing_unsupported_T5</th>\n",
       "      <th>Rearing_unsupported_T20</th>\n",
       "      <th>Rearing_unsupported_T55</th>\n",
       "      <th>Grooming_T5</th>\n",
       "      <th>Grooming_T20</th>\n",
       "      <th>Grooming_T55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LL1-B2B/2019-12-24_SPD/LL1-1_AgedB6-0420</td>\n",
       "      <td>0.040169</td>\n",
       "      <td>0.198675</td>\n",
       "      <td>-0.037979</td>\n",
       "      <td>0.052876</td>\n",
       "      <td>-0.003299</td>\n",
       "      <td>-0.010149</td>\n",
       "      <td>-0.055371</td>\n",
       "      <td>0.060958</td>\n",
       "      <td>-0.085216</td>\n",
       "      <td>...</td>\n",
       "      <td>68.20147</td>\n",
       "      <td>0.047222</td>\n",
       "      <td>0.059278</td>\n",
       "      <td>0.045596</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>0.018111</td>\n",
       "      <td>0.014250</td>\n",
       "      <td>0.024364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LL1-B2B/2020-01-02_SPD/LL1-1_AgedB6-0744</td>\n",
       "      <td>-0.296932</td>\n",
       "      <td>0.263532</td>\n",
       "      <td>0.100476</td>\n",
       "      <td>-0.147400</td>\n",
       "      <td>0.061194</td>\n",
       "      <td>-0.023672</td>\n",
       "      <td>-0.257141</td>\n",
       "      <td>0.099431</td>\n",
       "      <td>-0.173461</td>\n",
       "      <td>...</td>\n",
       "      <td>170.43687</td>\n",
       "      <td>0.088111</td>\n",
       "      <td>0.076472</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.011222</td>\n",
       "      <td>0.057806</td>\n",
       "      <td>0.114293</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.049485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LL1-B2B/2020-01-02_SPD/LL1-4_AgedB6-0746</td>\n",
       "      <td>0.013086</td>\n",
       "      <td>0.418435</td>\n",
       "      <td>0.148745</td>\n",
       "      <td>-0.155249</td>\n",
       "      <td>0.053694</td>\n",
       "      <td>-0.020380</td>\n",
       "      <td>-0.269689</td>\n",
       "      <td>0.178564</td>\n",
       "      <td>-0.192979</td>\n",
       "      <td>...</td>\n",
       "      <td>148.81530</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.048361</td>\n",
       "      <td>0.045515</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.015737</td>\n",
       "      <td>0.016556</td>\n",
       "      <td>0.017889</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LL1-B2B/2020-06-16_SPD/AgedB6-0411</td>\n",
       "      <td>-0.151999</td>\n",
       "      <td>0.127667</td>\n",
       "      <td>0.054410</td>\n",
       "      <td>0.010174</td>\n",
       "      <td>0.019283</td>\n",
       "      <td>-0.106259</td>\n",
       "      <td>-0.251713</td>\n",
       "      <td>0.064764</td>\n",
       "      <td>-0.170414</td>\n",
       "      <td>...</td>\n",
       "      <td>69.73327</td>\n",
       "      <td>0.029667</td>\n",
       "      <td>0.018194</td>\n",
       "      <td>0.031596</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.019694</td>\n",
       "      <td>0.024646</td>\n",
       "      <td>0.024778</td>\n",
       "      <td>0.016806</td>\n",
       "      <td>0.016273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LL1-B2B/2020-06-17_SPD/AgedB6-0420</td>\n",
       "      <td>-0.151820</td>\n",
       "      <td>0.409758</td>\n",
       "      <td>-0.160638</td>\n",
       "      <td>0.160570</td>\n",
       "      <td>0.014334</td>\n",
       "      <td>0.061617</td>\n",
       "      <td>-0.026318</td>\n",
       "      <td>0.140276</td>\n",
       "      <td>0.017099</td>\n",
       "      <td>...</td>\n",
       "      <td>72.26663</td>\n",
       "      <td>0.017667</td>\n",
       "      <td>0.024333</td>\n",
       "      <td>0.028747</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.005384</td>\n",
       "      <td>0.012333</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.017707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 415 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            NetworkFilename  latent_embedding_mean_0  \\\n",
       "0  LL1-B2B/2019-12-24_SPD/LL1-1_AgedB6-0420                 0.040169   \n",
       "1  LL1-B2B/2020-01-02_SPD/LL1-1_AgedB6-0744                -0.296932   \n",
       "2  LL1-B2B/2020-01-02_SPD/LL1-4_AgedB6-0746                 0.013086   \n",
       "3        LL1-B2B/2020-06-16_SPD/AgedB6-0411                -0.151999   \n",
       "4        LL1-B2B/2020-06-17_SPD/AgedB6-0420                -0.151820   \n",
       "\n",
       "   latent_embedding_mean_1  latent_embedding_mean_2  latent_embedding_mean_3  \\\n",
       "0                 0.198675                -0.037979                 0.052876   \n",
       "1                 0.263532                 0.100476                -0.147400   \n",
       "2                 0.418435                 0.148745                -0.155249   \n",
       "3                 0.127667                 0.054410                 0.010174   \n",
       "4                 0.409758                -0.160638                 0.160570   \n",
       "\n",
       "   latent_embedding_mean_4  latent_embedding_mean_5  latent_embedding_mean_6  \\\n",
       "0                -0.003299                -0.010149                -0.055371   \n",
       "1                 0.061194                -0.023672                -0.257141   \n",
       "2                 0.053694                -0.020380                -0.269689   \n",
       "3                 0.019283                -0.106259                -0.251713   \n",
       "4                 0.014334                 0.061617                -0.026318   \n",
       "\n",
       "   latent_embedding_mean_7  latent_embedding_mean_8  ...  \\\n",
       "0                 0.060958                -0.085216  ...   \n",
       "1                 0.099431                -0.173461  ...   \n",
       "2                 0.178564                -0.192979  ...   \n",
       "3                 0.064764                -0.170414  ...   \n",
       "4                 0.140276                 0.017099  ...   \n",
       "\n",
       "   grooming_duration_secs  Rearing_supported_T5  Rearing_supported_T20  \\\n",
       "0                68.20147              0.047222               0.059278   \n",
       "1               170.43687              0.088111               0.076472   \n",
       "2               148.81530              0.044444               0.048361   \n",
       "3                69.73327              0.029667               0.018194   \n",
       "4                72.26663              0.017667               0.024333   \n",
       "\n",
       "   Rearing_supported_T55  Rearing_unsupported_T5  Rearing_unsupported_T20  \\\n",
       "0               0.045596                0.002000                 0.002111   \n",
       "1               0.070101                0.011222                 0.057806   \n",
       "2               0.045515                0.008111                 0.009500   \n",
       "3               0.031596                0.001333                 0.019694   \n",
       "4               0.028747                0.005333                 0.002417   \n",
       "\n",
       "   Rearing_unsupported_T55  Grooming_T5  Grooming_T20  Grooming_T55  \n",
       "0                 0.004485     0.018111      0.014250      0.024364  \n",
       "1                 0.114293     0.022778      0.024194      0.049485  \n",
       "2                 0.015737     0.016556      0.017889      0.018061  \n",
       "3                 0.024646     0.024778      0.016806      0.016273  \n",
       "4                 0.005384     0.012333      0.005833      0.017707  \n",
       "\n",
       "[5 rows x 415 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = unsupervised_aging_dir / \"final_data_curation\"\n",
    "feature_sheet_filename = {\n",
    "    \"b6\": \"2026-01-28_UA_B6_masterdf.csv\",\n",
    "    \"do\": \"2026-01-28_UA_DO_masterdf-trans.csv\",\n",
    "    \"c\":  \"2025-12-30_UA_combined_masterdf.csv\"\n",
    "}[mode]\n",
    "\n",
    "feature_df = pd.read_csv(data_dir / feature_sheet_filename)\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "920fa9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 1223/1223 [00:27<00:00, 44.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed statistics for 1223 sequences\n",
      "Columns: 285 (95 unique syllables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_bout_length_0</th>\n",
       "      <th>total_duration_0</th>\n",
       "      <th>num_bouts_0</th>\n",
       "      <th>avg_bout_length_1</th>\n",
       "      <th>total_duration_1</th>\n",
       "      <th>num_bouts_1</th>\n",
       "      <th>avg_bout_length_2</th>\n",
       "      <th>total_duration_2</th>\n",
       "      <th>num_bouts_2</th>\n",
       "      <th>avg_bout_length_3</th>\n",
       "      <th>...</th>\n",
       "      <th>num_bouts_91</th>\n",
       "      <th>avg_bout_length_92</th>\n",
       "      <th>total_duration_92</th>\n",
       "      <th>num_bouts_92</th>\n",
       "      <th>avg_bout_length_93</th>\n",
       "      <th>total_duration_93</th>\n",
       "      <th>num_bouts_93</th>\n",
       "      <th>avg_bout_length_94</th>\n",
       "      <th>total_duration_94</th>\n",
       "      <th>num_bouts_94</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2.636364</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.851974</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv</th>\n",
       "      <td>3.700000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.769231</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13</td>\n",
       "      <td>3.868056</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv</th>\n",
       "      <td>3.787879</td>\n",
       "      <td>125.0</td>\n",
       "      <td>33</td>\n",
       "      <td>2.657895</td>\n",
       "      <td>101.0</td>\n",
       "      <td>38</td>\n",
       "      <td>2.774194</td>\n",
       "      <td>86.0</td>\n",
       "      <td>31</td>\n",
       "      <td>4.694158</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv</th>\n",
       "      <td>2.870968</td>\n",
       "      <td>623.0</td>\n",
       "      <td>217</td>\n",
       "      <td>2.574468</td>\n",
       "      <td>484.0</td>\n",
       "      <td>188</td>\n",
       "      <td>4.656250</td>\n",
       "      <td>745.0</td>\n",
       "      <td>160</td>\n",
       "      <td>3.674419</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv</th>\n",
       "      <td>2.250000</td>\n",
       "      <td>135.0</td>\n",
       "      <td>60</td>\n",
       "      <td>3.140351</td>\n",
       "      <td>179.0</td>\n",
       "      <td>57</td>\n",
       "      <td>2.928571</td>\n",
       "      <td>82.0</td>\n",
       "      <td>28</td>\n",
       "      <td>4.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               avg_bout_length_0  \\\n",
       "name                                                               \n",
       "LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv           3.000000   \n",
       "LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv           3.700000   \n",
       "LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv           3.787879   \n",
       "LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv           2.870968   \n",
       "LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv           2.250000   \n",
       "\n",
       "                                               total_duration_0  num_bouts_0  \\\n",
       "name                                                                           \n",
       "LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv              36.0           12   \n",
       "LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv              37.0           10   \n",
       "LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv             125.0           33   \n",
       "LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv             623.0          217   \n",
       "LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv             135.0           60   \n",
       "\n",
       "                                               avg_bout_length_1  \\\n",
       "name                                                               \n",
       "LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv           2.636364   \n",
       "LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv           1.750000   \n",
       "LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv           2.657895   \n",
       "LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv           2.574468   \n",
       "LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv           3.140351   \n",
       "\n",
       "                                               total_duration_1  num_bouts_1  \\\n",
       "name                                                                           \n",
       "LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv              29.0           11   \n",
       "LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv              14.0            8   \n",
       "LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv             101.0           38   \n",
       "LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv             484.0          188   \n",
       "LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv             179.0           57   \n",
       "\n",
       "                                               avg_bout_length_2  \\\n",
       "name                                                               \n",
       "LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv           2.500000   \n",
       "LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv           3.769231   \n",
       "LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv           2.774194   \n",
       "LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv           4.656250   \n",
       "LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv           2.928571   \n",
       "\n",
       "                                               total_duration_2  num_bouts_2  \\\n",
       "name                                                                           \n",
       "LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv              25.0           10   \n",
       "LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv              49.0           13   \n",
       "LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv              86.0           31   \n",
       "LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv             745.0          160   \n",
       "LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv              82.0           28   \n",
       "\n",
       "                                               avg_bout_length_3  ...  \\\n",
       "name                                                              ...   \n",
       "LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv           3.851974  ...   \n",
       "LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv           3.868056  ...   \n",
       "LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv           4.694158  ...   \n",
       "LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv           3.674419  ...   \n",
       "LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv           4.090909  ...   \n",
       "\n",
       "                                               num_bouts_91  \\\n",
       "name                                                          \n",
       "LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv             7   \n",
       "LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv             6   \n",
       "LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv             4   \n",
       "LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv             0   \n",
       "LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv            38   \n",
       "\n",
       "                                               avg_bout_length_92  \\\n",
       "name                                                                \n",
       "LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv                 0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv                 0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv                 0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv                 0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv                 0.0   \n",
       "\n",
       "                                               total_duration_92  \\\n",
       "name                                                               \n",
       "LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv                0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv                0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv                0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv                0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv                0.0   \n",
       "\n",
       "                                               num_bouts_92  \\\n",
       "name                                                          \n",
       "LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv             0   \n",
       "LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv             0   \n",
       "LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv             0   \n",
       "LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv             0   \n",
       "LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv             0   \n",
       "\n",
       "                                               avg_bout_length_93  \\\n",
       "name                                                                \n",
       "LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv                 0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv                 0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv                 0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv                 0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv                 0.0   \n",
       "\n",
       "                                               total_duration_93  \\\n",
       "name                                                               \n",
       "LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv                0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv                0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv                0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv                0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv                0.0   \n",
       "\n",
       "                                               num_bouts_93  \\\n",
       "name                                                          \n",
       "LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv             0   \n",
       "LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv             0   \n",
       "LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv             0   \n",
       "LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv             0   \n",
       "LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv             0   \n",
       "\n",
       "                                               avg_bout_length_94  \\\n",
       "name                                                                \n",
       "LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv                 0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv                 0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv                 0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv                 0.0   \n",
       "LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv                 0.0   \n",
       "\n",
       "                                               total_duration_94  num_bouts_94  \n",
       "name                                                                            \n",
       "LL1-B6__2023-07-06_MFS__DO2271_DO_F_25075.csv                0.0             0  \n",
       "LL1-B6__2023-07-06_MFS__DO2272_DO_F_25076.csv                0.0             0  \n",
       "LL1-B6__2023-07-06_MFS__DO2273_DO_F_25077.csv                0.0             0  \n",
       "LL1-B6__2023-07-06_MFS__DO2274_DO_F_25078.csv                0.0             0  \n",
       "LL1-B6__2023-07-06_MFS__DO2331_DO_M_25047.csv                0.0             0  \n",
       "\n",
       "[5 rows x 285 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def _get_syllable_frequency_statistics(agg_results, th: float = 0.0):\n",
    "    sequences = list(agg_results.values())\n",
    "    uniq = sorted({s for seq in sequences for s in seq})\n",
    "    \n",
    "    if th > 0.0:\n",
    "        global_counts = {s: 0 for s in uniq}\n",
    "        for seq in sequences:\n",
    "            for s in seq:\n",
    "                global_counts[s] += 1\n",
    "        total = sum(global_counts.values())\n",
    "        uniq = [s for s in uniq if total and global_counts[s] / total >= th]\n",
    "\n",
    "    if not uniq:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    idx = {s: i for i, s in enumerate(uniq)}\n",
    "    n = len(uniq)\n",
    "\n",
    "    out = {'name': []}\n",
    "    for s in uniq:\n",
    "        out[f\"avg_bout_length_{s}\"] = []\n",
    "        out[f\"total_duration_{s}\"] = []\n",
    "        out[f\"num_bouts_{s}\"] = []\n",
    "\n",
    "    for name, seq in tqdm(agg_results.items(), desc=\"Processing sequences\"):\n",
    "        out['name'].append(name)\n",
    "        \n",
    "        total_len = [0]*n\n",
    "        bout_cnt = [0]*n\n",
    "        sum_dur = [0.0]*n\n",
    "\n",
    "        prev = None\n",
    "        run_len = 0\n",
    "        for i, s in enumerate(seq):\n",
    "            if s == prev:\n",
    "                run_len += 1\n",
    "            else:\n",
    "                if prev in idx:\n",
    "                    j = idx[prev]\n",
    "                    total_len[j] += run_len\n",
    "                    bout_cnt[j] += 1\n",
    "                prev = s\n",
    "                run_len = 1\n",
    "            if s in idx:\n",
    "                sum_dur[idx[s]] += 1.0\n",
    "\n",
    "        if prev in idx:\n",
    "            j = idx[prev]\n",
    "            total_len[j] += run_len\n",
    "            bout_cnt[j] += 1\n",
    "\n",
    "        for j in range(n):\n",
    "            sum_dur[j] = float(total_len[j])\n",
    "\n",
    "        for j, s in enumerate(uniq):\n",
    "            abl = (total_len[j] / bout_cnt[j]) if bout_cnt[j] else 0.0\n",
    "            out[f\"avg_bout_length_{s}\"].append(abl)\n",
    "            out[f\"total_duration_{s}\"].append(sum_dur[j])\n",
    "            out[f\"num_bouts_{s}\"].append(int(bout_cnt[j]))\n",
    "\n",
    "    df = pd.DataFrame(out)\n",
    "    df.set_index('name', inplace=True)\n",
    "    return df\n",
    "\n",
    "syllable_stats_df = _get_syllable_frequency_statistics(agg_results)\n",
    "print(f\"Computed statistics for {len(syllable_stats_df)} sequences\")\n",
    "print(f\"Columns: {len(syllable_stats_df.columns)} ({len(syllable_stats_df.columns)//3} unique syllables)\")\n",
    "syllable_stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4323533d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 common syllable statistic columns between feature_df and syllable_stats_df\n",
      "Total columns in syllable_stats_df: 95\n",
      "Using only first 10 syllables (10 columns)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching rows: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:39<00:00,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MATCHING RESULTS:\n",
      "============================================================\n",
      "Total rows in feature_df: 1138\n",
      "SUCCESS (matched to exactly 1 element): 1074\n",
      "FAILURE (matched to 0 or >1 elements): 64\n",
      "Success rate: 94.38%\n",
      "============================================================\n",
      "\n",
      "First 5 failures:\n",
      "  1. Row 638 (/DO2279_DO_F_25083): 0 matches\n",
      "  2. Row 639 (/DO2343_DO_M_25058): 0 matches\n",
      "  3. Row 640 (/DO2342_DO_M_25057): 0 matches\n",
      "  4. Row 641 (/DO2281_DO_F_25085): 0 matches\n",
      "  5. Row 642 (/DO2282_DO_F_25086): 0 matches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def match_feature_df_to_stats(feature_df, syllable_stats_df, k=None):\n",
    "    stat_cols = [col for col in syllable_stats_df.columns \n",
    "                 if col.startswith('avg_bout_length_')]\n",
    "    \n",
    "    common_cols = [col for col in stat_cols if col in feature_df.columns]\n",
    "    \n",
    "    if k is not None:\n",
    "        syllable_ids = sorted(set([\n",
    "            int(col.split('_')[-1]) \n",
    "            for col in common_cols \n",
    "            if col.split('_')[-1].isdigit()\n",
    "        ]))[:k]\n",
    "        \n",
    "        common_cols = [col for col in common_cols \n",
    "                      if col.split('_')[-1].isdigit() and \n",
    "                         int(col.split('_')[-1]) in syllable_ids]\n",
    "    \n",
    "    print(f\"Found {len(common_cols)} common syllable statistic columns between feature_df and syllable_stats_df\")\n",
    "    print(f\"Total columns in syllable_stats_df: {len(stat_cols)}\")\n",
    "    if k is not None:\n",
    "        print(f\"Using only first {k} syllables ({len(common_cols)} columns)\")\n",
    "    \n",
    "    if len(common_cols) == 0:\n",
    "        print(\"WARNING: No common syllable statistic columns found!\")\n",
    "        return 0, len(feature_df), []\n",
    "    \n",
    "    success_count = 0\n",
    "    failure_count = 0\n",
    "    match_details = []\n",
    "    \n",
    "    for idx, row in tqdm(feature_df.iterrows(), total=len(feature_df), desc=\"Matching rows\"):\n",
    "        network_filename = row.get('NetworkFilename', f'row_{idx}')\n",
    "        feature_values = row[common_cols]\n",
    "        \n",
    "        matches = []\n",
    "        for stats_idx, stats_row in syllable_stats_df.iterrows():\n",
    "            stats_values = stats_row[common_cols]\n",
    "            \n",
    "            if all(abs(float(fv) - float(sv)) < 0.0001 if isinstance(fv, (int, float)) and isinstance(sv, (int, float)) \n",
    "                   else fv == sv \n",
    "                   for fv, sv in zip(feature_values, stats_values)):\n",
    "                matches.append(stats_idx)\n",
    "        \n",
    "        if len(matches) == 1:\n",
    "            success_count += 1\n",
    "            match_details.append({\n",
    "                'feature_row': idx,\n",
    "                'network_filename': network_filename,\n",
    "                'status': 'SUCCESS',\n",
    "                'matched_to': matches[0],\n",
    "                'num_matches': 1\n",
    "            })\n",
    "        else:\n",
    "            failure_count += 1\n",
    "            match_details.append({\n",
    "                'feature_row': idx,\n",
    "                'network_filename': network_filename,\n",
    "                'status': 'FAILURE',\n",
    "                'matched_to': matches if matches else None,\n",
    "                'num_matches': len(matches)\n",
    "            })\n",
    "    \n",
    "    return success_count, failure_count, match_details\n",
    "\n",
    "success_count, failure_count, match_details = match_feature_df_to_stats(feature_df, syllable_stats_df, k=10)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"MATCHING RESULTS:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total rows in feature_df: {len(feature_df)}\")\n",
    "print(f\"SUCCESS (matched to exactly 1 element): {success_count}\")\n",
    "print(f\"FAILURE (matched to 0 or >1 elements): {failure_count}\")\n",
    "print(f\"Success rate: {100*success_count/(success_count+failure_count):.2f}%\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "failures = [m for m in match_details if m['status'] == 'FAILURE']\n",
    "if failures:\n",
    "    print(f\"\\nFirst 5 failures:\")\n",
    "    for i, fail in enumerate(failures[:5]):\n",
    "        print(f\"  {i+1}. Row {fail['feature_row']} ({fail['network_filename']}): \"\n",
    "              f\"{fail['num_matches']} matches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "566147cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "NETWORK TO SYLLABLE MAPPING:\n",
      "============================================================\n",
      "Successfully mapped 1138 NetworkFilenames to syllable sequences\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NetworkFilename</th>\n",
       "      <th>matched_name</th>\n",
       "      <th>syllable_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LL1-B2B/2019-12-24_SPD/LL1-1_AgedB6-0420</td>\n",
       "      <td>LL1-B2B__2019-12-24_SPD__LL1-1_AgedB6-0420.csv</td>\n",
       "      <td>[11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LL1-B2B/2020-01-02_SPD/LL1-1_AgedB6-0744</td>\n",
       "      <td>LL1-B2B__2020-01-02_SPD__LL1-1_AgedB6-0744.csv</td>\n",
       "      <td>[35, 35, 35, 35, 44, 44, 13, 13, 13, 13, 13, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LL1-B2B/2020-01-02_SPD/LL1-4_AgedB6-0746</td>\n",
       "      <td>LL1-B2B__2020-01-02_SPD__LL1-4_AgedB6-0746.csv</td>\n",
       "      <td>[45, 45, 45, 45, 45, 45, 9, 18, 18, 18, 18, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LL1-B2B/2020-06-16_SPD/AgedB6-0411</td>\n",
       "      <td>LL1-B2B__2020-06-16_SPD__AgedB6-0411.csv</td>\n",
       "      <td>[30, 30, 30, 30, 30, 12, 12, 12, 12, 12, 54, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LL1-B2B/2020-06-17_SPD/AgedB6-0420</td>\n",
       "      <td>LL1-B2B__2020-06-17_SPD__AgedB6-0420.csv</td>\n",
       "      <td>[54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            NetworkFilename  \\\n",
       "0  LL1-B2B/2019-12-24_SPD/LL1-1_AgedB6-0420   \n",
       "1  LL1-B2B/2020-01-02_SPD/LL1-1_AgedB6-0744   \n",
       "2  LL1-B2B/2020-01-02_SPD/LL1-4_AgedB6-0746   \n",
       "3        LL1-B2B/2020-06-16_SPD/AgedB6-0411   \n",
       "4        LL1-B2B/2020-06-17_SPD/AgedB6-0420   \n",
       "\n",
       "                                     matched_name  \\\n",
       "0  LL1-B2B__2019-12-24_SPD__LL1-1_AgedB6-0420.csv   \n",
       "1  LL1-B2B__2020-01-02_SPD__LL1-1_AgedB6-0744.csv   \n",
       "2  LL1-B2B__2020-01-02_SPD__LL1-4_AgedB6-0746.csv   \n",
       "3        LL1-B2B__2020-06-16_SPD__AgedB6-0411.csv   \n",
       "4        LL1-B2B__2020-06-17_SPD__AgedB6-0420.csv   \n",
       "\n",
       "                                   syllable_sequence  \n",
       "0  [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 1...  \n",
       "1  [35, 35, 35, 35, 44, 44, 13, 13, 13, 13, 13, 1...  \n",
       "2  [45, 45, 45, 45, 45, 45, 9, 18, 18, 18, 18, 18...  \n",
       "3  [30, 30, 30, 30, 30, 12, 12, 12, 12, 12, 54, 5...  \n",
       "4  [54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 5...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_network_to_syllable_mapping(feature_df, agg_results, match_details):\n",
    "    mapping_data = []\n",
    "    \n",
    "    for match in match_details:\n",
    "        network_filename = match['network_filename']\n",
    "        \n",
    "        if match['status'] == 'SUCCESS':\n",
    "            matched_name = match['matched_to']\n",
    "            \n",
    "            if matched_name in agg_results:\n",
    "                syllable_sequence = agg_results[matched_name]\n",
    "                mapping_data.append({\n",
    "                    'NetworkFilename': network_filename,\n",
    "                    'matched_name': matched_name,\n",
    "                    'syllable_sequence': syllable_sequence\n",
    "                })\n",
    "        else:\n",
    "            # For unmatched elements, include them with empty syllable sequence\n",
    "            mapping_data.append({\n",
    "                'NetworkFilename': network_filename,\n",
    "                'matched_name': None,  # or '' if you prefer empty string\n",
    "                'syllable_sequence': []\n",
    "            })\n",
    "    \n",
    "    mapping_df = pd.DataFrame(mapping_data)\n",
    "    return mapping_df\n",
    "\n",
    "network_syllable_mapping = create_network_to_syllable_mapping(feature_df, agg_results, match_details)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"NETWORK TO SYLLABLE MAPPING:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Successfully mapped {len(network_syllable_mapping)} NetworkFilenames to syllable sequences\")\n",
    "print(f\"{'='*60}\")\n",
    "network_syllable_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ccd5ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_csv = network_syllable_mapping.copy()\n",
    "mapping_csv['syllable_sequence'] = mapping_csv['syllable_sequence'].apply(\n",
    "    lambda x: ','.join(map(str, x))\n",
    ")\n",
    "mapping_csv.to_csv(data_dir / f\"2025-01-28_{mode}_syll-seq.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81776223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
