{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a73dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/compsci/jgeorge/USERS/chouda/miniforge3/envs/keypoint_moseq_gpu/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2026-01-28 14:27:35.579288: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /projects/compsci/jgeorge/USERS/chouda/miniforge3/envs/keypoint_moseq_gpu/lib/python3.9/site-packages/cv2/../../lib64:/cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64\n",
      "2026-01-28 14:27:35.579306: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'plotly': 'https://cdn.plot.ly/plotly-2.18.0.min', 'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.3.2/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'gridstack': {'exports': 'GridStack'}}});\n      require([\"plotly\"], function(Plotly) {\n\twindow.Plotly = Plotly\n\ton_load()\n      })\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 5;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n    }    if (((window['Plotly'] !== undefined) && (!(window['Plotly'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/plotlyplot/plotly-2.18.0.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/js/tabulator.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/gridstack/gridstack@4.2.5/dist/gridstack-h5.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/jquery/jquery.slim.min.js\", \"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/plotlyplot/plotly-2.18.0.min.js\", \"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/js/tabulator.js\", \"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\", \"https://unpkg.com/@holoviz/panel@0.14.4/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/css/tabulator_simple.min.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/alerts.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/markdown.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/json.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/debugger.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/widgets.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/dataframe.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/loading.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/card.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arc:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n      background-size: auto calc(min(50%, 400px));\\n    }\\n    \");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.bk-root, .bk-root .bk:before, .bk-root .bk:after {\n",
       "  font-family: var(--jp-ui-font-size1);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Any, Dict, Mapping, Optional, Sequence\n",
    "\n",
    "import keypoint_moseq as kpms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d061a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_aging_dir = Path(os.environ[\"UNSUPERVISED_AGING\"])\n",
    "\n",
    "mode = \"do\"\n",
    "\n",
    "project_name, model_name = {\n",
    "    \"b6\": (\n",
    "        \"2025-07-03_kpms-v2\",\n",
    "        \"2025-07-07_model-2\"\n",
    "    ),\n",
    "    \"do\": (\n",
    "        \"2025-07-16_kpms-v3\",\n",
    "        \"2025-07-16_model-4\"\n",
    "    )\n",
    "}[mode]\n",
    "\n",
    "kpms_dir      = unsupervised_aging_dir / \"data/kpms_projects\"\n",
    "dataset_dir   = unsupervised_aging_dir / \"data/datasets/2025-12-19_missing-files/\"\n",
    "\n",
    "project_dir = kpms_dir / project_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd1b4348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num entries: 15\n"
     ]
    }
   ],
   "source": [
    "results = kpms.load_results(project_dir, model_name)\n",
    "print(f\"num entries: {len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52b9eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                         | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 35.98it/s]\n"
     ]
    }
   ],
   "source": [
    "def _get_latent_embedding_statistics() -> Dict[str, Sequence]:\n",
    "    stats = []\n",
    "    for _, info in tqdm(results.items()):\n",
    "        latent_embeddings = info[\"latent_state\"]\n",
    "\n",
    "        means   = latent_embeddings.mean(axis=0)\n",
    "        medians = np.median(latent_embeddings, axis=0)\n",
    "        stds    = latent_embeddings.std(axis=0, ddof=0)\n",
    "\n",
    "        features = np.concatenate((means, medians, stds))\n",
    "        stats.append(features)\n",
    "\n",
    "    trans = list(map(list, zip(*stats)))\n",
    "    feature_len = len(trans)\n",
    "    assert feature_len % 3 == 0\n",
    "\n",
    "    ret = {}\n",
    "    for i in range(feature_len):\n",
    "        label = (\"mean\" if i < feature_len // 3 else\n",
    "                 \"median\" if i < 2 * feature_len // 3 else \"std\")\n",
    "        ret[f\"latent_embedding_{label}_{i % (feature_len // 3)}\"] = trans[i]\n",
    "    return ret\n",
    "\n",
    "latent_embedding_statistics = _get_latent_embedding_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1b1129e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                         | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 68.14it/s]\n"
     ]
    }
   ],
   "source": [
    "def _get_syllable_frequency_statistics(th: float = 0.0) -> Dict[str, Sequence[float]]:\n",
    "    sequences = [info[\"syllable\"] for info in results.values()]\n",
    "    uniq = sorted({s for seq in sequences for s in seq})\n",
    "    if th > 0.0:\n",
    "        global_counts = {s: 0 for s in uniq}\n",
    "        for seq in sequences:\n",
    "            for s in seq:\n",
    "                global_counts[s] += 1\n",
    "        total = sum(global_counts.values())\n",
    "        uniq = [s for s in uniq if total and global_counts[s] / total >= th]\n",
    "\n",
    "    if not uniq:\n",
    "        return {}\n",
    "\n",
    "    idx = {s: i for i, s in enumerate(uniq)}\n",
    "    n = len(uniq)\n",
    "\n",
    "    out = {}\n",
    "    for s in uniq:\n",
    "        out[f\"avg_bout_length_{s}\"] = []\n",
    "        out[f\"total_duration_{s}\"] = []\n",
    "        out[f\"num_bouts_{s}\"] = []\n",
    "\n",
    "    for _, info in tqdm(results.items()):\n",
    "        seq = info[\"syllable\"]\n",
    "        dur = None\n",
    "        for k in (\"durations\", \"duration\", \"syllable_durations\", \"syllable_duration\"):\n",
    "            if k in info and hasattr(info[k], \"__len__\") and len(info[k]) == len(seq):\n",
    "                dur = info[k]\n",
    "                break\n",
    "\n",
    "        total_len = [0]*n\n",
    "        bout_cnt = [0]*n\n",
    "        sum_dur = [0.0]*n\n",
    "\n",
    "        prev = None\n",
    "        run_len = 0\n",
    "        for i, s in enumerate(seq):\n",
    "            if s == prev:\n",
    "                run_len += 1\n",
    "            else:\n",
    "                if prev in idx:\n",
    "                    j = idx[prev]\n",
    "                    total_len[j] += run_len\n",
    "                    bout_cnt[j] += 1\n",
    "                prev = s\n",
    "                run_len = 1\n",
    "            if s in idx and dur is not None:\n",
    "                sum_dur[idx[s]] += float(dur[i])\n",
    "\n",
    "        if prev in idx:\n",
    "            j = idx[prev]\n",
    "            total_len[j] += run_len\n",
    "            bout_cnt[j] += 1\n",
    "\n",
    "        if dur is None:\n",
    "            for j in range(n):\n",
    "                sum_dur[j] = float(total_len[j])\n",
    "\n",
    "        for j, s in enumerate(uniq):\n",
    "            abl = (total_len[j] / bout_cnt[j]) if bout_cnt[j] else 0.0\n",
    "            out[f\"avg_bout_length_{s}\"].append(abl)\n",
    "            out[f\"total_duration_{s}\"].append(sum_dur[j])\n",
    "            out[f\"num_bouts_{s}\"].append(int(bout_cnt[j]))\n",
    "\n",
    "    return out\n",
    "\n",
    "syllable_frequency_statistics = _get_syllable_frequency_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c33784b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 25.44it/s]\n"
     ]
    }
   ],
   "source": [
    "def _get_metasyllable_transition_matrix(\n",
    "    grouped_syllables: Optional[Mapping[str, Sequence[int]]] = None,\n",
    "    *,\n",
    "    ignore_unknown: bool = False,\n",
    "    include_frequencies: bool = True,\n",
    ") -> Dict[str, Sequence[float]]:\n",
    "    if grouped_syllables is None:\n",
    "        grouped_syllables = {}\n",
    "\n",
    "    sequences = [info[\"syllable\"] for info in results.values()]\n",
    "    vocab_size = max(s for seq in sequences for s in seq) + 1\n",
    "    all_indices = set(range(vocab_size))\n",
    "\n",
    "    seen = set()\n",
    "    for name, idxs in grouped_syllables.items():\n",
    "        bad = set(idxs) - all_indices\n",
    "        if bad:\n",
    "            raise ValueError(f\"Group '{name}' contains invalid indices {sorted(bad)}.\")\n",
    "        if seen.intersection(idxs):\n",
    "            raise ValueError(\"Duplicate indices detected across groups.\")\n",
    "        seen.update(idxs)\n",
    "\n",
    "    if not ignore_unknown:\n",
    "        unknown = sorted(all_indices - seen)\n",
    "        if unknown:\n",
    "            grouped_syllables = dict(grouped_syllables)\n",
    "            grouped_syllables[\"unknown\"] = unknown\n",
    "\n",
    "    names      = list(grouped_syllables.keys())\n",
    "    idx_sets   = [set(grouped_syllables[n]) for n in names]\n",
    "    g          = len(names)\n",
    "    feats      = {f\"transition_matrix_{a}_{b}\": [] for a in names for b in names if a != b}\n",
    "    if include_frequencies:\n",
    "        feats.update({f\"metasyllable_frequency_{n}\": [] for n in names})\n",
    "\n",
    "    idx_to_group = {}\n",
    "    for gi, s in enumerate(idx_sets):\n",
    "        for idx in s:\n",
    "            idx_to_group[idx] = gi\n",
    "\n",
    "    for _, info in tqdm(results.items()):\n",
    "        seq = info[\"syllable\"]\n",
    "        G = np.zeros((g, g), dtype=float)\n",
    "        for a, b in zip(seq[:-1], seq[1:]):\n",
    "            if a in idx_to_group and b in idx_to_group:\n",
    "                G[idx_to_group[a], idx_to_group[b]] += 1\n",
    "\n",
    "        np.fill_diagonal(G, 0)\n",
    "        row_sums = G.sum(axis=1, keepdims=True)\n",
    "        np.divide(G, row_sums, out=G, where=row_sums != 0)\n",
    "\n",
    "        for i, ai in enumerate(names):\n",
    "            for j, bj in enumerate(names):\n",
    "                if ai != bj:\n",
    "                    feats[f\"transition_matrix_{ai}_{bj}\"].append(G[i, j])\n",
    "\n",
    "        if include_frequencies:\n",
    "            counts = np.zeros(g, dtype=int)\n",
    "            for s in seq:\n",
    "                if s in idx_to_group:\n",
    "                    counts[idx_to_group[s]] += 1\n",
    "            total_tokens = len(seq)\n",
    "            freqs = counts / total_tokens if total_tokens else counts\n",
    "            for i, name in enumerate(names):\n",
    "                feats[f\"metasyllable_frequency_{name}\"].append(freqs[i])\n",
    "    return feats\n",
    "\n",
    "\n",
    "_metasyllable_groupings = {\n",
    "    \"b6\": {\n",
    "        \"kpms_dendrogram_0\": [0, 2, 10, 54, 35, 9, 30, 16, 26, 20, 6, 15],\n",
    "        \"kpms_dendrogram_1\": [24, 42, 52, 50, 48, 57, 33, 38, 60, 12, 58, 22, 43],\n",
    "        \"kpms_dendrogram_2\": [19, 59, 1, 3, 14, 18, 34, 5, 7, 46, 40, 4, 11, 45],\n",
    "        \"kpms_dendrogram_3\": [13, 8, 17, 39, 51, 21, 36, 61, 31, 49, 28, 44, 55, 37, 25, 32, 27, 56],\n",
    "        \"kpms_dendrogram_4\": [53, 62, 29, 41, 23, 47]\n",
    "    },\n",
    "    \"do\": {\n",
    "        \"kpms_dendogram_0\": [12, 20, 28, 14, 26],\n",
    "        \"kpms_dendogram_1\": [33, 23, 39, 13, 3, 11, 18],\n",
    "        \"kpms_dendogram_2\": [24, 9, 6, 25, 15, 21, 16, 35, 2, 10, 17],\n",
    "        \"kpms_dendogram_3\": [4, 34, 22, 30, 27, 29, 32, 19],\n",
    "        \"kpms_dendogram_4\": [5, 7, 8, 43, 55, 0, 1, 31],\n",
    "    },\n",
    "    \"combined\": {\n",
    "        \"kpms_dendrogram_0\": [41, 11, 23, 39, 22, 37, 28, 32, 5, 34, 1, 31, 20, 13, 25],\n",
    "        \"kpms_dendrogram_1\": [45, 46],\n",
    "        \"kpms_dendrogram_2\": [44, 50, 4, 2, 18, 53, 24, 8, 35, 14, 15, 10, 17, 26, 30, 7, 43, 9, 42, 48, 6, 29],\n",
    "        \"kpms_dendrogram_3\": [47, 27, 36],\n",
    "        \"kpms_dendrogram_4\": [40, 21, 12, 33, 16, 0, 3, 19, 38],\n",
    "    }\n",
    "}[mode]\n",
    "\n",
    "# c_1204\n",
    "# _metasyllable_groupings = {\n",
    "#     \"kpms_dendrogram_0\": [19, 30],\n",
    "#     \"kpms_dendrogram_1\": [40, 34, 3, 5, 12, 31, 18, 22, 39, 2, 10],\n",
    "#     \"kpms_dendrogram_2\": [38, 46, 29, 11, 42, 33, 7, 13, 0, 17, 1, 9, 24, 36, 26, 16, 32, 20, 8, 21],\n",
    "#     \"kpms_dendrogram_3\": [27, 35],\n",
    "#     \"kpms_dendrogram_4\": [23, 37, 25, 28, 15, 6, 4, 14]\n",
    "# }\n",
    "\n",
    "kpms_dendrogram_metasyllable_transition_matrix = _get_metasyllable_transition_matrix(_metasyllable_groupings, ignore_unknown=True, include_frequencies=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a10f98c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'latent_embedding_mean_0',\n",
       " 'latent_embedding_mean_1',\n",
       " 'latent_embedding_mean_2',\n",
       " 'latent_embedding_mean_3',\n",
       " 'latent_embedding_mean_4',\n",
       " 'latent_embedding_mean_5',\n",
       " 'latent_embedding_mean_6',\n",
       " 'latent_embedding_mean_7',\n",
       " 'latent_embedding_mean_8',\n",
       " 'latent_embedding_mean_9',\n",
       " 'latent_embedding_mean_10',\n",
       " 'latent_embedding_mean_11',\n",
       " 'latent_embedding_median_0',\n",
       " 'latent_embedding_median_1',\n",
       " 'latent_embedding_median_2',\n",
       " 'latent_embedding_median_3',\n",
       " 'latent_embedding_median_4',\n",
       " 'latent_embedding_median_5',\n",
       " 'latent_embedding_median_6',\n",
       " 'latent_embedding_median_7',\n",
       " 'latent_embedding_median_8',\n",
       " 'latent_embedding_median_9',\n",
       " 'latent_embedding_median_10',\n",
       " 'latent_embedding_median_11',\n",
       " 'latent_embedding_std_0',\n",
       " 'latent_embedding_std_1',\n",
       " 'latent_embedding_std_2',\n",
       " 'latent_embedding_std_3',\n",
       " 'latent_embedding_std_4',\n",
       " 'latent_embedding_std_5',\n",
       " 'latent_embedding_std_6',\n",
       " 'latent_embedding_std_7',\n",
       " 'latent_embedding_std_8',\n",
       " 'latent_embedding_std_9',\n",
       " 'latent_embedding_std_10',\n",
       " 'latent_embedding_std_11',\n",
       " 'avg_bout_length_0',\n",
       " 'total_duration_0',\n",
       " 'num_bouts_0',\n",
       " 'avg_bout_length_1',\n",
       " 'total_duration_1',\n",
       " 'num_bouts_1',\n",
       " 'avg_bout_length_2',\n",
       " 'total_duration_2',\n",
       " 'num_bouts_2',\n",
       " 'avg_bout_length_3',\n",
       " 'total_duration_3',\n",
       " 'num_bouts_3',\n",
       " 'avg_bout_length_4',\n",
       " 'total_duration_4',\n",
       " 'num_bouts_4',\n",
       " 'avg_bout_length_5',\n",
       " 'total_duration_5',\n",
       " 'num_bouts_5',\n",
       " 'avg_bout_length_6',\n",
       " 'total_duration_6',\n",
       " 'num_bouts_6',\n",
       " 'avg_bout_length_7',\n",
       " 'total_duration_7',\n",
       " 'num_bouts_7',\n",
       " 'avg_bout_length_8',\n",
       " 'total_duration_8',\n",
       " 'num_bouts_8',\n",
       " 'avg_bout_length_9',\n",
       " 'total_duration_9',\n",
       " 'num_bouts_9',\n",
       " 'avg_bout_length_10',\n",
       " 'total_duration_10',\n",
       " 'num_bouts_10',\n",
       " 'avg_bout_length_11',\n",
       " 'total_duration_11',\n",
       " 'num_bouts_11',\n",
       " 'avg_bout_length_12',\n",
       " 'total_duration_12',\n",
       " 'num_bouts_12',\n",
       " 'avg_bout_length_13',\n",
       " 'total_duration_13',\n",
       " 'num_bouts_13',\n",
       " 'avg_bout_length_14',\n",
       " 'total_duration_14',\n",
       " 'num_bouts_14',\n",
       " 'avg_bout_length_15',\n",
       " 'total_duration_15',\n",
       " 'num_bouts_15',\n",
       " 'avg_bout_length_16',\n",
       " 'total_duration_16',\n",
       " 'num_bouts_16',\n",
       " 'avg_bout_length_17',\n",
       " 'total_duration_17',\n",
       " 'num_bouts_17',\n",
       " 'avg_bout_length_18',\n",
       " 'total_duration_18',\n",
       " 'num_bouts_18',\n",
       " 'avg_bout_length_19',\n",
       " 'total_duration_19',\n",
       " 'num_bouts_19',\n",
       " 'avg_bout_length_20',\n",
       " 'total_duration_20',\n",
       " 'num_bouts_20',\n",
       " 'avg_bout_length_21',\n",
       " 'total_duration_21',\n",
       " 'num_bouts_21',\n",
       " 'avg_bout_length_22',\n",
       " 'total_duration_22',\n",
       " 'num_bouts_22',\n",
       " 'avg_bout_length_23',\n",
       " 'total_duration_23',\n",
       " 'num_bouts_23',\n",
       " 'avg_bout_length_24',\n",
       " 'total_duration_24',\n",
       " 'num_bouts_24',\n",
       " 'avg_bout_length_25',\n",
       " 'total_duration_25',\n",
       " 'num_bouts_25',\n",
       " 'avg_bout_length_26',\n",
       " 'total_duration_26',\n",
       " 'num_bouts_26',\n",
       " 'avg_bout_length_27',\n",
       " 'total_duration_27',\n",
       " 'num_bouts_27',\n",
       " 'avg_bout_length_28',\n",
       " 'total_duration_28',\n",
       " 'num_bouts_28',\n",
       " 'avg_bout_length_29',\n",
       " 'total_duration_29',\n",
       " 'num_bouts_29',\n",
       " 'avg_bout_length_30',\n",
       " 'total_duration_30',\n",
       " 'num_bouts_30',\n",
       " 'avg_bout_length_31',\n",
       " 'total_duration_31',\n",
       " 'num_bouts_31',\n",
       " 'avg_bout_length_32',\n",
       " 'total_duration_32',\n",
       " 'num_bouts_32',\n",
       " 'avg_bout_length_33',\n",
       " 'total_duration_33',\n",
       " 'num_bouts_33',\n",
       " 'avg_bout_length_34',\n",
       " 'total_duration_34',\n",
       " 'num_bouts_34',\n",
       " 'avg_bout_length_35',\n",
       " 'total_duration_35',\n",
       " 'num_bouts_35',\n",
       " 'avg_bout_length_36',\n",
       " 'total_duration_36',\n",
       " 'num_bouts_36',\n",
       " 'avg_bout_length_37',\n",
       " 'total_duration_37',\n",
       " 'num_bouts_37',\n",
       " 'avg_bout_length_38',\n",
       " 'total_duration_38',\n",
       " 'num_bouts_38',\n",
       " 'avg_bout_length_39',\n",
       " 'total_duration_39',\n",
       " 'num_bouts_39',\n",
       " 'avg_bout_length_40',\n",
       " 'total_duration_40',\n",
       " 'num_bouts_40',\n",
       " 'avg_bout_length_41',\n",
       " 'total_duration_41',\n",
       " 'num_bouts_41',\n",
       " 'avg_bout_length_42',\n",
       " 'total_duration_42',\n",
       " 'num_bouts_42',\n",
       " 'avg_bout_length_43',\n",
       " 'total_duration_43',\n",
       " 'num_bouts_43',\n",
       " 'avg_bout_length_44',\n",
       " 'total_duration_44',\n",
       " 'num_bouts_44',\n",
       " 'avg_bout_length_45',\n",
       " 'total_duration_45',\n",
       " 'num_bouts_45',\n",
       " 'avg_bout_length_46',\n",
       " 'total_duration_46',\n",
       " 'num_bouts_46',\n",
       " 'avg_bout_length_47',\n",
       " 'total_duration_47',\n",
       " 'num_bouts_47',\n",
       " 'avg_bout_length_48',\n",
       " 'total_duration_48',\n",
       " 'num_bouts_48',\n",
       " 'avg_bout_length_49',\n",
       " 'total_duration_49',\n",
       " 'num_bouts_49',\n",
       " 'avg_bout_length_50',\n",
       " 'total_duration_50',\n",
       " 'num_bouts_50',\n",
       " 'avg_bout_length_51',\n",
       " 'total_duration_51',\n",
       " 'num_bouts_51',\n",
       " 'avg_bout_length_52',\n",
       " 'total_duration_52',\n",
       " 'num_bouts_52',\n",
       " 'avg_bout_length_53',\n",
       " 'total_duration_53',\n",
       " 'num_bouts_53',\n",
       " 'avg_bout_length_54',\n",
       " 'total_duration_54',\n",
       " 'num_bouts_54',\n",
       " 'avg_bout_length_55',\n",
       " 'total_duration_55',\n",
       " 'num_bouts_55',\n",
       " 'avg_bout_length_56',\n",
       " 'total_duration_56',\n",
       " 'num_bouts_56',\n",
       " 'avg_bout_length_57',\n",
       " 'total_duration_57',\n",
       " 'num_bouts_57',\n",
       " 'avg_bout_length_58',\n",
       " 'total_duration_58',\n",
       " 'num_bouts_58',\n",
       " 'avg_bout_length_59',\n",
       " 'total_duration_59',\n",
       " 'num_bouts_59',\n",
       " 'avg_bout_length_60',\n",
       " 'total_duration_60',\n",
       " 'num_bouts_60',\n",
       " 'avg_bout_length_61',\n",
       " 'total_duration_61',\n",
       " 'num_bouts_61',\n",
       " 'avg_bout_length_62',\n",
       " 'total_duration_62',\n",
       " 'num_bouts_62',\n",
       " 'avg_bout_length_63',\n",
       " 'total_duration_63',\n",
       " 'num_bouts_63',\n",
       " 'avg_bout_length_64',\n",
       " 'total_duration_64',\n",
       " 'num_bouts_64',\n",
       " 'avg_bout_length_65',\n",
       " 'total_duration_65',\n",
       " 'num_bouts_65',\n",
       " 'avg_bout_length_66',\n",
       " 'total_duration_66',\n",
       " 'num_bouts_66',\n",
       " 'avg_bout_length_67',\n",
       " 'total_duration_67',\n",
       " 'num_bouts_67',\n",
       " 'avg_bout_length_68',\n",
       " 'total_duration_68',\n",
       " 'num_bouts_68',\n",
       " 'avg_bout_length_69',\n",
       " 'total_duration_69',\n",
       " 'num_bouts_69',\n",
       " 'avg_bout_length_70',\n",
       " 'total_duration_70',\n",
       " 'num_bouts_70',\n",
       " 'avg_bout_length_71',\n",
       " 'total_duration_71',\n",
       " 'num_bouts_71',\n",
       " 'avg_bout_length_72',\n",
       " 'total_duration_72',\n",
       " 'num_bouts_72',\n",
       " 'avg_bout_length_73',\n",
       " 'total_duration_73',\n",
       " 'num_bouts_73',\n",
       " 'avg_bout_length_74',\n",
       " 'total_duration_74',\n",
       " 'num_bouts_74',\n",
       " 'avg_bout_length_75',\n",
       " 'total_duration_75',\n",
       " 'num_bouts_75',\n",
       " 'avg_bout_length_76',\n",
       " 'total_duration_76',\n",
       " 'num_bouts_76',\n",
       " 'avg_bout_length_77',\n",
       " 'total_duration_77',\n",
       " 'num_bouts_77',\n",
       " 'avg_bout_length_78',\n",
       " 'total_duration_78',\n",
       " 'num_bouts_78',\n",
       " 'avg_bout_length_79',\n",
       " 'total_duration_79',\n",
       " 'num_bouts_79',\n",
       " 'avg_bout_length_80',\n",
       " 'total_duration_80',\n",
       " 'num_bouts_80',\n",
       " 'avg_bout_length_81',\n",
       " 'total_duration_81',\n",
       " 'num_bouts_81',\n",
       " 'avg_bout_length_82',\n",
       " 'total_duration_82',\n",
       " 'num_bouts_82',\n",
       " 'avg_bout_length_83',\n",
       " 'total_duration_83',\n",
       " 'num_bouts_83',\n",
       " 'avg_bout_length_84',\n",
       " 'total_duration_84',\n",
       " 'num_bouts_84',\n",
       " 'avg_bout_length_87',\n",
       " 'total_duration_87',\n",
       " 'num_bouts_87',\n",
       " 'avg_bout_length_88',\n",
       " 'total_duration_88',\n",
       " 'num_bouts_88',\n",
       " 'avg_bout_length_89',\n",
       " 'total_duration_89',\n",
       " 'num_bouts_89',\n",
       " 'avg_bout_length_91',\n",
       " 'total_duration_91',\n",
       " 'num_bouts_91',\n",
       " 'transition_matrix_kpms_dendogram_0_kpms_dendogram_1',\n",
       " 'transition_matrix_kpms_dendogram_0_kpms_dendogram_2',\n",
       " 'transition_matrix_kpms_dendogram_0_kpms_dendogram_3',\n",
       " 'transition_matrix_kpms_dendogram_0_kpms_dendogram_4',\n",
       " 'transition_matrix_kpms_dendogram_1_kpms_dendogram_0',\n",
       " 'transition_matrix_kpms_dendogram_1_kpms_dendogram_2',\n",
       " 'transition_matrix_kpms_dendogram_1_kpms_dendogram_3',\n",
       " 'transition_matrix_kpms_dendogram_1_kpms_dendogram_4',\n",
       " 'transition_matrix_kpms_dendogram_2_kpms_dendogram_0',\n",
       " 'transition_matrix_kpms_dendogram_2_kpms_dendogram_1',\n",
       " 'transition_matrix_kpms_dendogram_2_kpms_dendogram_3',\n",
       " 'transition_matrix_kpms_dendogram_2_kpms_dendogram_4',\n",
       " 'transition_matrix_kpms_dendogram_3_kpms_dendogram_0',\n",
       " 'transition_matrix_kpms_dendogram_3_kpms_dendogram_1',\n",
       " 'transition_matrix_kpms_dendogram_3_kpms_dendogram_2',\n",
       " 'transition_matrix_kpms_dendogram_3_kpms_dendogram_4',\n",
       " 'transition_matrix_kpms_dendogram_4_kpms_dendogram_0',\n",
       " 'transition_matrix_kpms_dendogram_4_kpms_dendogram_1',\n",
       " 'transition_matrix_kpms_dendogram_4_kpms_dendogram_2',\n",
       " 'transition_matrix_kpms_dendogram_4_kpms_dendogram_3']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _merge_features(\n",
    "    features: Sequence[Dict[str, Sequence[Any]]]\n",
    ") -> pd.DataFrame:\n",
    "    names = list(map(lambda path: path.removesuffix(\".csv\"), results.keys()))\n",
    "    merged_features = reduce(operator.or_, [{\"name\": names}] + features, {})\n",
    "    return pd.DataFrame(merged_features)\n",
    "\n",
    "unsupervised_features_df = _merge_features([\n",
    "    latent_embedding_statistics, \n",
    "    syllable_frequency_statistics,\n",
    "    # old_syllable_frequency_statistics,\n",
    "    kpms_dendrogram_metasyllable_transition_matrix\n",
    "])\n",
    "list(unsupervised_features_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2638f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to /projects/kumar-lab/miaod/projects/unsupervised-aging/final_data_curation/2025-01-28_do_15.csv\n"
     ]
    }
   ],
   "source": [
    "path_name = unsupervised_aging_dir / \"final_data_curation\" / f\"2025-01-28_{mode}_15.csv\"\n",
    "unsupervised_features_df.to_csv(path_name, index=False)\n",
    "print(f\"Saved to {path_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e01839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc79ffa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
